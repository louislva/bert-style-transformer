{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace, Sequence, ByteLevel\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = ByteLevel()\n",
    "tokenizer.decoder = ByteLevelDecoder()\n",
    "\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[START]\", \"[END]\", \"[PAD]\"], vocab_size=16384)\n",
    "\n",
    "files = [\"corpus150.txt\"]\n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "#tokenizer.encode('[START] A duck is a carnivorous animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset file of size 1537774\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import codecs\n",
    "from timeit import timeit\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        filename = 'corpus150.txt'\n",
    "        \n",
    "        self.file = codecs.open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "        self.file_length = os.stat(filename).st_size\n",
    "        \n",
    "        print('Loaded dataset file of size', self.file_length)\n",
    "        \n",
    "    def sample_batch(self, n=32, length=240):\n",
    "        # sample a lot of strings of certain length\n",
    "        strs = []\n",
    "        for i in range(n):\n",
    "            self.file.seek(random.randrange(0, self.file_length - length))\n",
    "            strs.append(self.file.read(length))\n",
    "        \n",
    "        # encode with tokenizer\n",
    "        x = [encoding.ids for encoding in tokenizer.encode_batch(strs)]\n",
    "        \n",
    "        # shorten the long ones\n",
    "        min_len = min(map(len, x))\n",
    "        x = [ids[0:min_len] for ids in x]\n",
    "        \n",
    "        # put it into pytorch preferred format (torch.tensor, with shape (sequence, batch))\n",
    "        x = torch.tensor(x)\n",
    "        x = x.transpose(1, 0)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "dataset = Data()\n",
    "\n",
    "#timeit(dataset.sample_batch, number=100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(torch.rand((2,2)) > 0.8).float() * torch.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "def checker_board(d_model):\n",
    "    half = (d_model) // 2\n",
    "    texture = torch.cat([\n",
    "        torch.ones((half, 1)),\n",
    "        torch.zeros((half, 1))\n",
    "    ], dim=1).view((-1,))\n",
    "    \n",
    "    return texture\n",
    "\n",
    "print(checker_board(8))\n",
    "print(-checker_board(8) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_embedding(x):\n",
    "        # x: (pos, n, i)\n",
    "        \n",
    "        length = x.shape[0]\n",
    "        batch_size = x.shape[1]\n",
    "        d_model = x.shape[2]\n",
    "\n",
    "        i = torch.arange(0, d_model).view((1, 1, -1)).expand(length, -1, d_model).to(device).float()\n",
    "        pos = torch.arange(0, length).view((-1, 1, 1)).expand(length, -1, d_model).to(device).float()\n",
    "        \n",
    "        z = pos / 10000 ** (i / d_model)\n",
    "        \n",
    "        sin = torch.sin(z)\n",
    "        cos = torch.cos(z)\n",
    "        \n",
    "        sin_mask = checker_board(d_model).to(device)\n",
    "        cos_mask = -sin_mask + 1\n",
    "                \n",
    "        pe = (sin_mask * sin) + (cos_mask * cos)\n",
    "        pe = pe.expand(length, batch_size, d_model)\n",
    "        \n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703,\n",
       "        703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703, 703,\n",
       "        703, 703], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.1, embedding_dim=512, heads=8, num_layers=3):\n",
    "        super(Model, self).__init__()\n",
    "        # config\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.heads = heads\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.start_token = torch.tensor([[1]]).to(device)\n",
    "        \n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(num_embeddings=16384, embedding_dim=embedding_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(embedding_dim, heads, dim_feedforward=2048, dropout=dropout)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(embedding_dim, heads, dim_feedforward=2048, dropout=dropout)\n",
    "        \n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "        self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=3)\n",
    "        \n",
    "        self.unembedding = nn.Linear(512, 16384)\n",
    "        self.unembedding.weight.data = self.embedding.weight.data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        source = pos_embedding(x)\n",
    "        target = pos_embedding(torch.cat([\n",
    "            self.embedding(self.start_token).expand(1, source.shape[1], -1),\n",
    "            x\n",
    "        ], dim=0)[:-1])\n",
    "        \n",
    "        source_mask = (torch.rand((source.shape[0], source.shape[1], 1)) > 0.1).float().expand(-1, -1, self.embedding_dim).to(device)\n",
    "        source = source * source_mask\n",
    "        \n",
    "        target_mask = torch.triu(torch.full((target.shape[0], target.shape[0]), float('-inf')), diagonal=1).to(device)\n",
    "        \n",
    "        memory = self.encoder(source)\n",
    "        output = self.decoder(target, memory, tgt_mask=target_mask)\n",
    "        \n",
    "        output = self.unembedding(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def use(self, source, duration=20):\n",
    "        source = pos_embedding(self.embedding(source))\n",
    "        memory = self.encoder(source)\n",
    "        \n",
    "        target = [1]\n",
    "        \n",
    "        for i in range(duration):\n",
    "            target_embedded = pos_embedding(self.embedding(torch.tensor(target, dtype=torch.long).view((-1, 1)).to(device)))\n",
    "            output = self.unembedding(self.decoder(target_embedded, memory))[-1, 0]\n",
    "            output = torch.distributions.categorical.Categorical(probs=F.softmax(output, dim=0)).sample()\n",
    "            #print(output_dist)\n",
    "            target.append(output.item())\n",
    "        \n",
    "        return target\n",
    "        \n",
    "    def beam(self, source, k=15, length=30):\n",
    "        # encode\n",
    "        source = self.embedding(source)\n",
    "        source = pos_embedding(source)\n",
    "        memory = self.encoder(source)\n",
    "        # copy memory for each k we'll be processing\n",
    "        memory = memory.expand(-1, k, -1)\n",
    "        \n",
    "        # keep [k] active branches of [length]\n",
    "        target = torch.zeros((length, k), dtype=torch.long).to(device)\n",
    "        scores = torch.zeros((length, k)).to(device)\n",
    "        # every branches root is a start token\n",
    "        target[0, :] = 1\n",
    "        scores[0, :] = 0\n",
    "        \n",
    "        # decode\n",
    "        for i in range(1, length):\n",
    "            # make predictions for each current branch\n",
    "            target_embedding = pos_embedding(self.embedding(target[:i]))\n",
    "            output = self.unembedding(self.decoder(target_embedding, memory))[-1:]\n",
    "            \n",
    "            # find [k] best branches from each current branch.\n",
    "            y = torch.topk(output, k=k, dim=2)\n",
    "            \n",
    "            # find the value of current branches as they are\n",
    "            current_evidence = scores[:i].sum(dim=0).view((1, k)).unsqueeze(2).expand(1, -1, k)\n",
    "            \n",
    "            # add that to the value of each possible branch for each current branch\n",
    "            branch_evidence = current_evidence + y.values\n",
    "            \n",
    "            # decide which possibilities should be leaf of the new [k] current branches based on the highest total value\n",
    "            y_topk = torch.topk(branch_evidence.view((-1)), k=k)\n",
    "            \n",
    "            # find out which current root branch the new leafs belong to\n",
    "            current_k_root = y_topk.indices // k\n",
    "            \n",
    "            # replace target & scores with the best leafs, preceded by their current branch\n",
    "            new_target = torch.cat(\n",
    "                [\n",
    "                    target[0:i, current_k_root], # current branch that the leaf comes from\n",
    "                    y.indices.view((-1,))[y_topk.indices].view((1, k)) # leaf\n",
    "                ],\n",
    "                dim=0\n",
    "            )\n",
    "            new_scores = torch.cat(\n",
    "                [\n",
    "                    scores[0:i, current_k_root],\n",
    "                    y.values.view((-1,))[y_topk.indices].view((1, k))\n",
    "                ],\n",
    "                dim=0\n",
    "            )\n",
    "            \n",
    "            target[:i+1] = new_target\n",
    "            scores[:i+1] = new_scores\n",
    "            \n",
    "        return target[:, scores.sum(dim=0).argmax()]\n",
    "            \n",
    "        \n",
    "        \n",
    "model = Model().to(device)\n",
    "#model.load_state_dict(torch.load('state_dicts/model'))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
    "\n",
    "model.beam(\n",
    "    torch.tensor([[34]], dtype=torch.long).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-7f3b5029ee2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    x = dataset.sample_batch(n=64, length=320).to(device)\n",
    "    \n",
    "    y = model.forward(x)\n",
    "    \n",
    "    #print(y[1,0])\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()(y.view((-1, 16384)), x.reshape((-1)))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('loss', loss)    \n",
    "    #print(x.shape, y.shape)\n",
    "    #print(x[0:5, 0], y[0:5, 0].argmax(dim=1))\n",
    "    print(tokenizer.decode(x[:, 0].tolist()))\n",
    "    print('================================')\n",
    "    print(tokenizer.decode(y[:, 0].argmax(dim=1).tolist()))\n",
    "    clear_output(wait=True)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'state_dicts/bert3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers numbers'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "tokenizer.decode(\n",
    "    model.beam(\n",
    "        torch.tensor(tokenizer.encode('Animals are [UNK]').ids, dtype=torch.long).view((-1, 1)).to(device),\n",
    "        k=15,\n",
    "        length=20\n",
    "    ).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
